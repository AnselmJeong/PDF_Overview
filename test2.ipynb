{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert pdf to markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pymupdf4llm import to_markdown\n",
    "import pymupdf\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm_model = ChatOpenAI(model=\"grok-beta\", base_url=\"https://api.x.ai/v1\", api_key=os.getenv(\"XAI_API_KEY\"))\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def get_first_page_image(pdf_path: str):\n",
    "    pdf_document = pymupdf.open(pdf_path)\n",
    "    pixmap = pdf_document[0].get_pixmap()\n",
    "\n",
    "    return pixmap.tobytes()\n",
    "\n",
    "\n",
    "def convert_to_markdown(pdf_path: str, write_to_file: bool = False) -> str:\n",
    "    temp_path = Path(pdf_path)\n",
    "    output_dir = temp_path.parent\n",
    "    if temp_path.exists() and temp_path.suffix == \".pdf\":\n",
    "        file_name = temp_path.stem\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"File {pdf_path} does not exist or is not a PDF file\")\n",
    "\n",
    "    md_text = to_markdown(pdf_path)\n",
    "    if write_to_file:\n",
    "        with open(f\"{output_dir}/{file_name}.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(md_text)\n",
    "    return md_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# md_text = convert_to_markdown(\"docs/restructured.pdf\")\n",
    "first_page_image = get_first_page_image(\"docs/restraint.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(first_page_image, width=800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml\n",
    "\n",
    "with open(\"prompts/prompts.toml\", \"r\") as f:\n",
    "    prompts = toml.load(f)\n",
    "\n",
    "essentials_prompt_template = prompts[\"extract_essentials\"][\"prompt\"]\n",
    "sections_prompt_template = prompts[\"extract_sections\"][\"prompt\"]\n",
    "section_details_prompt_template = prompts[\"extract_section_details\"][\"prompt\"]\n",
    "metadata_prompt_template = prompts[\"extract_metadata\"][\"prompt\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", metadata_prompt_template),\n",
    "    (\"user\", \"{first_page_image}\"),\n",
    "])\n",
    "\n",
    "essentials_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", essentials_prompt_template),\n",
    "    (\"user\", \"{text}\"),\n",
    "])\n",
    "\n",
    "sections_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", sections_prompt_template),\n",
    "    (\"user\", \"{text}\"),\n",
    "])\n",
    "\n",
    "section_details_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        section_details_prompt_template,\n",
    "    ),\n",
    "    (\"user\", \"{text}\"),\n",
    "])\n",
    "\n",
    "\n",
    "metadata_chain = metadata_prompt | llm_model | StrOutputParser()\n",
    "essentials_chain = essentials_prompt | llm_model | StrOutputParser()\n",
    "sections_chain = sections_prompt | llm_model | StrOutputParser()\n",
    "section_details_chain = section_details_prompt | llm_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract title, authors, affilication from the first page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata(first_page_image: bytes) -> dict:\n",
    "    metadata = metadata_chain.invoke({\"first_page_image\": first_page_image})\n",
    "    metadata = metadata.replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "    return json.loads(metadata)\n",
    "\n",
    "\n",
    "metadata = extract_metadata(first_page_image)\n",
    "metadata\n",
    "# Get summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quote_essentials(essentials: str) -> str:\n",
    "    essentials_quoted = \"\"\n",
    "    for split in essentials.split(\"\\n\\n\"):\n",
    "        essentials_quoted += f\"> {split}\\n\\n\"\n",
    "    return essentials_quoted\n",
    "\n",
    "\n",
    "def extract_essentials(text: str) -> str:\n",
    "    essentials = essentials_chain.invoke({\"text\": text})\n",
    "    return quote_essentials(essentials)\n",
    "\n",
    "\n",
    "def extract_section_titles(text: str) -> list[str]:\n",
    "    section_titles = sections_chain.invoke({\"text\": text}).split(\"\\n\")\n",
    "    return section_titles\n",
    "\n",
    "\n",
    "def extract_section_details(text, section_titles):\n",
    "    section_details = []\n",
    "    for section_title in section_titles:\n",
    "        section_detail = section_details_chain.invoke({\n",
    "            \"text\": text,\n",
    "            \"section_title\": section_title,\n",
    "        })\n",
    "        section_details.append(f\"## {section_title}\\n\\n{section_detail}\")\n",
    "\n",
    "    return section_details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overview(pdf_path: str, write_to_file: bool = True) -> str:\n",
    "    temp_path = Path(pdf_path)\n",
    "    output_dir = temp_path.parent\n",
    "    if temp_path.exists() and temp_path.suffix == \".pdf\":\n",
    "        file_name = temp_path.stem\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"File {pdf_path} does not exist or is not a PDF file\")\n",
    "\n",
    "    md_text = convert_to_markdown(pdf_path)\n",
    "    metadata = extract_metadata(first_page_image)\n",
    "    essentials = extract_essentials(md_text)\n",
    "    section_titles = extract_section_titles(md_text)\n",
    "    section_details = extract_section_details(md_text, section_titles)\n",
    "\n",
    "    all_output = \"\"\n",
    "\n",
    "    all_output += f\"# {metadata['title']}\\n\\n\"\n",
    "    all_output += f\"### {', '.join(metadata['authors'])}\\n\\n\"\n",
    "    all_output += f\"#### {metadata['affiliation']}\\n\\n\"\n",
    "    all_output += f\"{essentials}\\n\\n\"\n",
    "    all_output += \"## Abstract\\n\\n\"\n",
    "    all_output += f\"{metadata['abstract']}\\n\\n\"\n",
    "    all_output += \"\\n\\n\".join(section_details)\n",
    "    if write_to_file:\n",
    "        with open(f\"{output_dir}/{file_name}.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(all_output)\n",
    "\n",
    "    return all_output\n",
    "\n",
    "\n",
    "get_overview(\"docs/coercive.pdf\", write_to_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(metadata_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!      |"
     ]
    }
   ],
   "source": [
    "from utils.process_image import extract_metadata\n",
    "\n",
    "answer = extract_metadata(first_page_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Exploring Psychiatric Patient Restraints: Balancing Safety, Ethics, and Patient Rights in Mental Healthcare',\n",
       " 'authors': ['Fayaz Ahmed Paul',\n",
       "  'Asim Ur Rehman Ganie',\n",
       "  'Danishwar Rasool Dar',\n",
       "  'Priyanka Saikia',\n",
       "  'Indrajit Banerjee'],\n",
       " 'affiliation': 'Department of Psychiatry: Social Work, LGB Regional Institute of Mental Health, Tezpur, Assam, India',\n",
       " 'abstract': 'This paper examines the use of restraints in psychiatric care, balancing safety and ethical considerations with patient rights.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_text = \"abkjljlkjlkjlkjlkklklklkjlkjjk \\n\\n REFERECes \\n\\n 1. 2. 3. 4. 5. 6. 7. 8. 9. 10.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_text = md_text[: md_text.lower().find(\"references\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abkjljlkjlkjlkjlkklklklkjlkjjk \\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
